{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Tabular Reinforcement Learning**\n",
    "\n",
    "# SARSA on FrozenLake environment\n",
    "\n",
    "## Non-Evaluables Practical Exercices\n",
    "\n",
    "This is a non-evaluable practical exercise, but it is recommended that students complete it fully and individually, since it is an important part of the learning process.\n",
    "\n",
    "The solution will be available, although it is not recommended that students consult the solution until they have completed the exercise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The FrozenLake environment\n",
    "\n",
    "In this activity, we are going to implement the **Value Iteration** algorithm on [Frozen Lake](https://gymnasium.farama.org/environments/toy_text/frozen_lake/) environment.\n",
    "\n",
    "Main characteristics:\n",
    "- The game starts with the player at location [0,0] of the frozen lake grid world with the goal located at far extent of the world e.g. [3,3] for the 4x4 environment.\n",
    "- Holes in the ice are distributed in set locations when using a pre-determined map or in random locations when a random map is generated.\n",
    "- The player makes moves until they reach the goal or fall in a hole.\n",
    "- The lake is slippery (unless disabled) so the player may move perpendicular to the intended direction sometimes (see _is_slippery_ param).\n",
    "\n",
    "<img src=\"https://gymnasium.farama.org/_images/frozen_lake.gif\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SARSA\n",
    "\n",
    "<u>Question 1</u>: : **Implement the *SARSA* algorithm** explained in the \"Temporal Difference Learning\" module using the following parameters:\n",
    "\n",
    "- Number of episodes = 1000000\n",
    "- *learning rate* = 0.5\n",
    "- *discount factor* = 1\n",
    "- *epsilon* = 0.05  \n",
    "\n",
    "<u>Question 2</u>: Once you have coded the algorithm, try different **values for the hyperparameters** and comment the best ones (providing an empirical comparison):\n",
    "\n",
    "- Number of episodes\n",
    "- *learning rate* \n",
    "- *discount factor* \n",
    "- *epsilon*\n",
    "\n",
    "<u>Question 3</u>: Try to solve the same environment but using a _8 x 8_ grid (also in slippery mode):\n",
    "> gym.make(ENV_NAME, desc=None, map_name=\"8x8\", is_slippery=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space is Discrete(4) \n",
      "Observation space is Discrete(16) \n",
      "Reward range is (0, 1) \n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "# params\n",
    "ENV_NAME = \"FrozenLake-v1\"\n",
    "GAMMA = 0.9\n",
    "TEST_EPISODES = 20\n",
    "\n",
    "# definig the environment\n",
    "env = gym.make(ENV_NAME, desc=None, map_name=\"4x4\", is_slippery=False)\n",
    "\n",
    "print(\"Action space is {} \".format(env.action_space))\n",
    "print(\"Observation space is {} \".format(env.observation_space))\n",
    "print(\"Reward range is {} \".format(env.reward_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_policy(Q, state, nA, epsilon):\n",
    "    '''\n",
    "    Create a policy where epsilon dictates the probability of a random action being carried out.\n",
    "\n",
    "    :param Q: link state -> action value (dictionary)\n",
    "    :param state: state in which the agent is (int)\n",
    "    :param nA: number of actions (int)\n",
    "    :param epsilon: possibility of random movement (float)\n",
    "    :return: probability of each action (list) d\n",
    "    '''\n",
    "\n",
    "    probs = np.ones(nA)\n",
    "    \n",
    "    return probs\n",
    "\n",
    "\n",
    "def SARSA(episodes, learning_rate, discount, epsilon):\n",
    "    '''\n",
    "    Learn to solve the environment using the SARSA algorithm\n",
    "\n",
    "    :param episodes: Number of episodes (int)\n",
    "    :param learning_rate: Learning rate (float [0, 1])\n",
    "    :param discount: Discount factor (float [0, 1])\n",
    "    :param epsilon: chance that random movement is required (float [0, 1])\n",
    "    :return: x,y number of episodes and number of steps\n",
    "    :Q: action value function\n",
    "    '''\n",
    "\n",
    "    # Link actions to states\n",
    "    Q = defaultdict(lambda: np.zeros(env.action_space.n))\n",
    "\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Solution</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def epsilon_greedy_policy(Q, state, nA, epsilon):\n",
    "    '''\n",
    "    Create a policy where epsilon dictates the probability of a random action being carried out.\n",
    "\n",
    "    :param Q: link state -> action value (dictionary)\n",
    "    :param state: state in which the agent is (int)\n",
    "    :param nA: number of actions (int)\n",
    "    :param epsilon: possibility of random movement (float)\n",
    "    :return: probability of each action (list) d\n",
    "    '''\n",
    "    probs = np.ones(nA, dtype=float) * epsilon / nA\n",
    "    best_action = np.argmax(Q[state])\n",
    "    probs[best_action] += (1.0 - epsilon)\n",
    "\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import sys\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "# writer\n",
    "writer = SummaryWriter(comment=\"-mc_control\")\n",
    "\n",
    "\n",
    "def SARSA(env, episodes:int, learning_rate:float, discount:float, epsilon:float):\n",
    "    '''\n",
    "    Learn to solve the environment using the SARSA algorithm\n",
    "\n",
    "    :param episodes: Number of episodes (int)\n",
    "    :param learning_rate: Learning rate (float [0, 1])\n",
    "    :param discount: Discount factor (float [0, 1])\n",
    "    :param epsilon: chance that random movement is required (float [0, 1])\n",
    "    :return: x,y number of episodes and number of steps\n",
    "    :Q: action value function\n",
    "    '''\n",
    "\n",
    "    # Link actions to states\n",
    "    Q = defaultdict(lambda: np.zeros(env.action_space.n))\n",
    "\n",
    "    # Rewards\n",
    "    y = np.zeros(episodes)\n",
    "    a = defaultdict(lambda: 0)\n",
    "    wins = 0\n",
    "    \n",
    "    for episode in range(episodes):\n",
    "        state, _ = env.reset()\n",
    "        done = False\n",
    "        # Select and execute an action\n",
    "        probs = epsilon_greedy_policy(Q, state, env.action_space.n, epsilon)\n",
    "        action = np.random.choice(np.arange(len(probs)), p=probs)\n",
    "        \n",
    "        # train bucle for each episode\n",
    "        step = 1\n",
    "        total_reward = 0\n",
    "        while not done:\n",
    "            # TODO\n",
    "            a[action] += 1\n",
    "        \n",
    "            # Execute action\n",
    "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated\n",
    "            \n",
    "            # Select and execute action\n",
    "            probs = epsilon_greedy_policy(Q, next_state, env.action_space.n, epsilon)\n",
    "            next_action = np.random.choice(np.arange(len(probs)), p=probs)\n",
    "           \n",
    "            # Update TD\n",
    "            td_target = reward + discount * Q[next_state][next_action]\n",
    "            td_error = td_target - Q[state][action]\n",
    "            Q[state][action] += learning_rate * td_error\n",
    "\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                y[episode] = total_reward\n",
    "                if reward > 0:\n",
    "                    wins += 1\n",
    "                break\n",
    "\n",
    "            state = next_state\n",
    "            action = next_action\n",
    "            step += 1\n",
    "            \n",
    "        # write to summary\n",
    "        writer.add_scalar(\"reward\", total_reward, episode)\n",
    "\n",
    "        # We print which episode we are in, useful for debugging.\n",
    "        if episode % 100 == 0 and episode > 0:\n",
    "            print(\"\\rEpisode {:8d}/{:8d} - Average reward {:.2f}\".format(episode, episodes, np.average(y[(episode-100):episode])), end=\"\")\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "    print(\"\")\n",
    "    print(a)\n",
    "    print(wins)\n",
    "                 \n",
    "    return y, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode      900/    1000 - Average reward 0.32\n",
      "defaultdict(<function SARSA.<locals>.<lambda> at 0x7f9ba2447280>, {0: 5229, 2: 2557, 3: 2281, 1: 2699})\n",
      "193\n"
     ]
    }
   ],
   "source": [
    "y, q = SARSA(env, episodes=1000, learning_rate=0.5, discount=1.0, epsilon=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State  0: [0.21659466 0.29478631 0.26565657 0.26426961]\n",
      "State  1: [0.31077241 0.         0.29520492 0.08358048]\n",
      "State  2: [0.29420305 0.57918905 0.28324697 0.26766848]\n",
      "State  3: [0.27521733 0.         0.1342232  0.1474857 ]\n",
      "State  4: [0.14071249 0.41000329 0.         0.27746482]\n",
      "State  5: [0. 0. 0. 0.]\n",
      "State  6: [0.         0.71571134 0.         0.29092772]\n",
      "State  7: [0. 0. 0. 0.]\n",
      "State  8: [0.39557796 0.         0.59591422 0.24651677]\n",
      "State  9: [0.52471059 0.76136254 0.87436283 0.        ]\n",
      "State 10: [0.67693493 0.78877849 0.         0.16474817]\n",
      "State 11: [0. 0. 0. 0.]\n",
      "State 12: [0. 0. 0. 0.]\n",
      "State 13: [0.         0.43016438 0.99914061 0.7525202 ]\n",
      "State 14: [0.73627285 0.83908721 1.         0.39340102]\n",
      "State 15: [0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# print the Q action-value function\n",
    "def print_Q_function(q):\n",
    "    for k in sorted(q.keys()):\n",
    "        print(\"State {:2d}: {}\".format(k, q[k]))\n",
    "\n",
    "print_Q_function(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execution of an episode following the optimal policy\n",
    "def execute_episode_SARSA(q, env, debug=False):\n",
    "    obs, _ = env.reset()\n",
    "    t, total_reward, done = 0, 0, False\n",
    "\n",
    "    if debug:\n",
    "        print(\"Obs initial: {} \".format(obs))\n",
    "\n",
    "    while True: \n",
    "        # Choose an action following the optimal policy (no epsilon-greedy)\n",
    "        arr = np.array(q[obs])\n",
    "        action = arr.argmax()\n",
    "       \n",
    "        # Execute the action and wait for the response from the environment\n",
    "        new_obs, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        obs = new_obs\n",
    "        if debug:\n",
    "            print(\"Action: {} -> Obs: {} and reward: {}\".format(action, obs, reward))\n",
    "\n",
    "        total_reward += reward\n",
    "        t += 1\n",
    "        if done:\n",
    "            break\n",
    "   \n",
    "    print(\"Episode finished after {} timesteps and reward was {} \".format(t, total_reward))\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obs initial: 0 \n",
      "Action: 1 -> Obs: 4 and reward: 0.0\n",
      "Action: 1 -> Obs: 8 and reward: 0.0\n",
      "Action: 2 -> Obs: 9 and reward: 0.0\n",
      "Action: 2 -> Obs: 10 and reward: 0.0\n",
      "Action: 1 -> Obs: 14 and reward: 0.0\n",
      "Action: 2 -> Obs: 15 and reward: 1.0\n",
      "Episode finished after 6 timesteps and reward was 1.0 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute_episode_SARSA(q, env, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Average reward is 1.0 (20 episodes)\n",
      "Environment solved!\n"
     ]
    }
   ],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "writer = SummaryWriter(comment=\"-sarsa\")\n",
    "\n",
    "total_reward = 0.0\n",
    "for iter_no in range(TEST_EPISODES):\n",
    "    reward = execute_episode_SARSA(q, env)\n",
    "    writer.add_scalar(\"reward\", reward, iter_no)\n",
    "    total_reward += reward\n",
    "\n",
    "avg_reward = total_reward / TEST_EPISODES\n",
    "print(\"Average reward is {} ({} episodes)\".format(avg_reward, TEST_EPISODES))\n",
    "if reward > 0.80:\n",
    "    print(\"Environment solved!\")\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters grid search\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_episodes(env, q, num_episodes):\n",
    "    total_reward = 0.0\n",
    "    for iter_no in range(num_episodes):\n",
    "        reward = execute_episode_SARSA(q, env)\n",
    "        total_reward += reward\n",
    "\n",
    "    avg_reward = total_reward / TEST_EPISODES\n",
    "    print(\"Average reward is {} ({} episodes)\".format(avg_reward, TEST_EPISODES))\n",
    "    if reward > 0.80:\n",
    "        print(\"Environment solved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon = 0.0\n",
      "Episode      900/    1000 - Average reward 0.00\n",
      "defaultdict(<function SARSA.<locals>.<lambda> at 0x7f9ba2af3790>, {0: 100000})\n",
      "0\n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Average reward is 0.0 (20 episodes)\n",
      "Epsilon = 0.1\n",
      "Episode      900/    1000 - Average reward 0.00\n",
      "defaultdict(<function SARSA.<locals>.<lambda> at 0x7f9ba24471f0>, {0: 64856, 1: 1740, 3: 1720, 2: 1720})\n",
      "0\n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Average reward is 0.0 (20 episodes)\n",
      "Epsilon = 0.2\n",
      "Episode      900/    1000 - Average reward 0.00\n",
      "defaultdict(<function SARSA.<locals>.<lambda> at 0x7f9ba2adaee0>, {0: 39159, 3: 2248, 1: 2308, 2: 2235})\n",
      "1\n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Average reward is 0.0 (20 episodes)\n",
      "Epsilon = 0.30000000000000004\n",
      "Episode      900/    1000 - Average reward 0.00\n",
      "defaultdict(<function SARSA.<locals>.<lambda> at 0x7f9ba2af3820>, {0: 24484, 3: 2343, 2: 2320, 1: 2420})\n",
      "0\n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Average reward is 0.0 (20 episodes)\n",
      "Epsilon = 0.4\n",
      "Episode      900/    1000 - Average reward 0.00\n",
      "defaultdict(<function SARSA.<locals>.<lambda> at 0x7f9ba24410d0>, {2: 2250, 0: 15634, 1: 2256, 3: 2205})\n",
      "0\n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Average reward is 0.0 (20 episodes)\n",
      "Epsilon = 0.5\n",
      "Episode      900/    1000 - Average reward 0.27\n",
      "defaultdict(<function SARSA.<locals>.<lambda> at 0x7f9ba2af3820>, {2: 2631, 0: 6260, 3: 2447, 1: 2545})\n",
      "159\n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Average reward is 1.0 (20 episodes)\n",
      "Environment solved!\n",
      "Epsilon = 0.6000000000000001\n",
      "Episode      900/    1000 - Average reward 0.11\n",
      "defaultdict(<function SARSA.<locals>.<lambda> at 0x7f9ba2af3820>, {0: 7139, 2: 2281, 3: 2201, 1: 2304})\n",
      "34\n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Average reward is 0.0 (20 episodes)\n",
      "Epsilon = 0.7000000000000001\n",
      "Episode      900/    1000 - Average reward 0.13\n",
      "defaultdict(<function SARSA.<locals>.<lambda> at 0x7f9ba2af3790>, {1: 2425, 0: 3053, 3: 2059, 2: 2130})\n",
      "94\n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Episode finished after 100 timesteps and reward was 0.0 \n",
      "Average reward is 0.0 (20 episodes)\n",
      "Epsilon = 0.8\n",
      "Episode      900/    1000 - Average reward 0.10\n",
      "defaultdict(<function SARSA.<locals>.<lambda> at 0x7f9ba2adaee0>, {3: 2116, 1: 2266, 2: 2164, 0: 2533})\n",
      "61\n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Average reward is 1.0 (20 episodes)\n",
      "Environment solved!\n",
      "Epsilon = 0.9\n",
      "Episode      900/    1000 - Average reward 0.01\n",
      "defaultdict(<function SARSA.<locals>.<lambda> at 0x7f9ba2af3820>, {2: 1979, 0: 2406, 1: 1976, 3: 1945})\n",
      "27\n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Episode finished after 6 timesteps and reward was 1.0 \n",
      "Average reward is 1.0 (20 episodes)\n",
      "Environment solved!\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 20\n",
    "\n",
    "for epsilon in np.arange (start=0, stop=1.0, step=0.1):\n",
    "    print(\"Epsilon = {}\".format(epsilon))\n",
    "    y, q = SARSA(env, episodes=1000, learning_rate=0.5, discount=1.0, epsilon=epsilon)\n",
    "    test_episodes(env, q, num_episodes)\n",
    "          \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "M2.883_PEC1_.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
